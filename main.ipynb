{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1JMp22fk-XB"
      },
      "source": [
        "# **Personalized Product Recommendations with ML PySpark and OpenAI Embeddings**\n",
        "\n",
        "> This Project is designed to:  \n",
        "- **build scalable recommendation systems** to enhance customer experiences and drive sales.  \n",
        "- Construct a **data processing pipeline** using **PySpark**.  \n",
        "- Implement **K-means clustering** with **OpenAI text embeddings**.  \n",
        "- Develop a **recommendation system** that suggests products based on user behavior.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSq024bak3oY"
      },
      "source": [
        "### Task 1 - Set up the project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ2xad8skFPi"
      },
      "source": [
        "Installing the needed modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9TysdMWOkEfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611f8922-6716-4a90-fc52-a37af94fb012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.16.2\n",
            "  Downloading openai-1.16.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (4.12.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.16.2) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.16.2) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.16.2) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.16.2) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.16.2) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.16.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.16.2) (2.27.1)\n",
            "Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.4\n",
            "    Uninstalling openai-1.57.4:\n",
            "      Successfully uninstalled openai-1.57.4\n",
            "Successfully installed openai-1.16.2 python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.16.2 python-dotenv pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW-TNHnokK9R"
      },
      "source": [
        "Imporint the modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "471JgJHHkM4j"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import concat_ws\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import ArrayType, FloatType\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler, PCA\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B9C7nK-n_PH"
      },
      "source": [
        "Setup the OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "41IBnP7WoDul"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "# Loading API key and organization ID from dotenv file\n",
        "load_dotenv(dotenv_path='apikey.env.txt')\n",
        "\n",
        "# Retrieving API Key from the env variables\n",
        "APIKEY = os.getenv(\"APIKEY\")\n",
        "\n",
        "# Check if the APIKEY is loaded correctly\n",
        "if APIKEY is None:\n",
        "  raise ValueError(\"API key not found.\")\n",
        "\n",
        "openai.api_key = APIKEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZdObqeMkOig"
      },
      "source": [
        "Create a Spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_Qv5GsOYjg6-",
        "outputId": "6a9d0c03-b610-4cfb-dff9-d27971daecdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7dc53fd73ac0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c8742ea6ec73:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ProductRecommenderSystem</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ProductRecommenderSystem\").getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrVs7c7VkdAU"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7nN4tpI2kpJH",
        "outputId": "c4f230d8-62c4-45eb-b038-1943efb27a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+\n",
            "|product_id|               title|         description|\n",
            "+----------+--------------------+--------------------+\n",
            "|        P0|Men's 3X Large Ca...|This heavyweight,...|\n",
            "|        P1|Turmode 30 ft. RP...|If you need more ...|\n",
            "|        P2|Large Tapestry Bo...|Polyester cover r...|\n",
            "|        P3|16-Gauge-Sinks Ve...|It features a rec...|\n",
            "|        P4|Men's Crazy Horse...|This 9 in. black ...|\n",
            "|        P5|Mariana 6 ft. Mul...|With robust struc...|\n",
            "|        P6|5 gal. #650C-2 Po...|BEHR PRO i300 Sem...|\n",
            "|        P7|7/8 in. x 4-1/2 i...|DEWALT High Perfo...|\n",
            "|        P8|  Ring Gold Bar Cart|This Ring Bar Car...|\n",
            "|        P9|Traditional Silve...|This transitional...|\n",
            "|       P10|15 in. x 59 in. O...|Its easy to add a...|\n",
            "|       P11|1 qt. #350F-7 Wil...|BEHR PREMIUM PLUS...|\n",
            "|       P12|Anthracite Cordle...|BlindsAvenue ligh...|\n",
            "|       P13|SlimGrip 78-Inch ...|Luverne SlimGrip ...|\n",
            "|       P14|6 in. x 28 in. x ...|Our Rustic Collec...|\n",
            "|       P15|Espresso Cordless...|\"The 2-1/2 in. Co...|\n",
            "|       P16|5 gal. #BL-W10 Ma...|BEHR PREMIUM PLUS...|\n",
            "|       P17|Eleyn 26 in. Indo...|This lighted chro...|\n",
            "|       P18|1 qt. #M400-5 Bab...|BEHR PREMIUM PLUS...|\n",
            "|       P19|10 in. x 4 in. x ...|Our faux wood bea...|\n",
            "+----------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = \"products_dataset.csv\"\n",
        "\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3iLfvXQqxg1"
      },
      "source": [
        "List of 8 products recently viewed by the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2tAbjKgqxKs"
      },
      "outputs": [],
      "source": [
        "recently_viewed_products = [\n",
        "    'P316',\n",
        "    'P333',\n",
        "    'P1115',\n",
        "    'P1691',\n",
        "    'P1082',\n",
        "    'P397',\n",
        "    'P1441',\n",
        "    'P1054',\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8GVRghclHxs"
      },
      "source": [
        "### Task 2 - Prepare the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgtmOENUl6uS"
      },
      "source": [
        "Combine `title` and `description` Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pIV-mogSlLPa",
        "outputId": "36844cb7-23b3-4b26-d943-b33d06e5627d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+--------------------+\n",
            "|product_id|               title|         description|       combined_text|\n",
            "+----------+--------------------+--------------------+--------------------+\n",
            "|        P0|Men's 3X Large Ca...|This heavyweight,...|Men's 3X Large Ca...|\n",
            "|        P1|Turmode 30 ft. RP...|If you need more ...|Turmode 30 ft. RP...|\n",
            "|        P2|Large Tapestry Bo...|Polyester cover r...|Large Tapestry Bo...|\n",
            "|        P3|16-Gauge-Sinks Ve...|It features a rec...|16-Gauge-Sinks Ve...|\n",
            "|        P4|Men's Crazy Horse...|This 9 in. black ...|Men's Crazy Horse...|\n",
            "|        P5|Mariana 6 ft. Mul...|With robust struc...|Mariana 6 ft. Mul...|\n",
            "|        P6|5 gal. #650C-2 Po...|BEHR PRO i300 Sem...|5 gal. #650C-2 Po...|\n",
            "|        P7|7/8 in. x 4-1/2 i...|DEWALT High Perfo...|7/8 in. x 4-1/2 i...|\n",
            "|        P8|  Ring Gold Bar Cart|This Ring Bar Car...|Ring Gold Bar Car...|\n",
            "|        P9|Traditional Silve...|This transitional...|Traditional Silve...|\n",
            "|       P10|15 in. x 59 in. O...|Its easy to add a...|15 in. x 59 in. O...|\n",
            "|       P11|1 qt. #350F-7 Wil...|BEHR PREMIUM PLUS...|1 qt. #350F-7 Wil...|\n",
            "|       P12|Anthracite Cordle...|BlindsAvenue ligh...|Anthracite Cordle...|\n",
            "|       P13|SlimGrip 78-Inch ...|Luverne SlimGrip ...|SlimGrip 78-Inch ...|\n",
            "|       P14|6 in. x 28 in. x ...|Our Rustic Collec...|6 in. x 28 in. x ...|\n",
            "|       P15|Espresso Cordless...|\"The 2-1/2 in. Co...|Espresso Cordless...|\n",
            "|       P16|5 gal. #BL-W10 Ma...|BEHR PREMIUM PLUS...|5 gal. #BL-W10 Ma...|\n",
            "|       P17|Eleyn 26 in. Indo...|This lighted chro...|Eleyn 26 in. Indo...|\n",
            "|       P18|1 qt. #M400-5 Bab...|BEHR PREMIUM PLUS...|1 qt. #M400-5 Bab...|\n",
            "|       P19|10 in. x 4 in. x ...|Our faux wood bea...|10 in. x 4 in. x ...|\n",
            "+----------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = df.withColumn(\"combined_text\", concat_ws(\" \", df.title, df.description))\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbgC0Iy5rO4M"
      },
      "source": [
        "get the combined_text column and convert it into a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nLNhzZNQmaQN",
        "outputId": "61a00cf6-4820-41bd-8386-60bef51d9bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Men's 3X Large Carbon Heather Cotton/Polyester Rain Defender Paxton Heavyweight Hooded Zip-Front Sweatshirt This heavyweight, water-repellent hooded sweatshirt has a zip front for fast layering. ORIGINAL FIT. 13 oz., 75% cotton/25% polyester blend with Rain Defender durable water repellent. Attached, jersey-lined three-piece hood with drawcord closure. Antique-finish brass front zipper. Two front hand-warmer pockets have a hidden security pocket inside. Stretchable, spandex-reinforced rib-knit cuffs and waistband. Locker loop facilitates hanging.\", \"Turmode 30 ft. RP TNC Female to RP TNC Male Adapter Cable If you need more length between your existing wireless device and Hi-Gain Antenna, this is the product for you. It's compatible with most Wi-Fi Antennas, so it is easy for you to extend your wireless network. Just replace your existing cable that runs between your wireless device and Antenna and you're ready to use your network with extended range.\", 'Large Tapestry Bolster Bed Polyester cover resembling rich Italian tapestries wraps your pet in comfort and style. 100% recycled polyester high loft MemoryFiber fill keeps pets elevated off cold floors for relief on tired joints and pressure points. A great fit for pets up to 100 lbs. Zippered removable cover is machine washable in cold water only. To dry, use a delicate cycle or gentle setting with very low heat.', '16-Gauge-Sinks Vessel Sink in White with Faucet It features a rectangle shape. This vessel set is designed to be installed as a undermount vessel set. It is constructed with ceramic. This vessel set comes with an enamel glaze finish in White color. It is designed for a deck mount faucet.']\n"
          ]
        }
      ],
      "source": [
        "list_combined_text = df.select(\"combined_text\").rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "print(list_combined_text[:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR-Nbn3jrN6F"
      },
      "source": [
        "Use OpenAI text embedding model to create the vector embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2Lc54tWKmldh",
        "outputId": "b502ec8c-9de8-4fd4-b58f-921f3d8e3ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-876476ae916f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call the Embedding API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = openai.Embedding.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_combined_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m  \u001b[0;31m# Use a supported model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ],
      "source": [
        "# Call the Embedding API\n",
        "response = openai.Embedding.create(\n",
        "    input=list_combined_text,\n",
        "    model=\"text-embedding-ada-002\"  # Use a supported model\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHuwaf1us-l1"
      },
      "source": [
        "Let't put the embedding vectors into our original dataframe\n",
        "\n",
        "Convert embedding vectors list into a Pyspark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_column_names = [f\"embedding_{i}\" for i in range(len(embedding_vectors[0]))]"
      ],
      "metadata": {
        "id": "EQRJmM3RhmK1",
        "outputId": "98022bcf-93c6-4256-d37f-1c8c43a82051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'embedding_vectors' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-581fdc567f3c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_column_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"embedding_{i}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_vectors' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add unique `row_id` to each row in the pysaprk dataframe"
      ],
      "metadata": {
        "id": "aGzNmNuen5ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai migrate"
      ],
      "metadata": {
        "id": "VoQDjRGmne3o",
        "outputId": "d247c00b-bb1c-4fa4-a271-7d8e4bb798d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-38-424aeda019d3>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-424aeda019d3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    openai migrate\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add unique `row_id` to each row in our main pyspark dataframe `df`"
      ],
      "metadata": {
        "id": "S2DhHJRXoJo7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8V61FsgnkLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's join the two dataframes"
      ],
      "metadata": {
        "id": "pgvT5LdZoPp3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTELw9sknntv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY4One5i4VXh"
      },
      "source": [
        "### Task 3 - Cluster products using K-means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVGiIJZC22Yo"
      },
      "source": [
        "Assemble the 512 Embedding Columns into a Single 'features' Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCBdSiRb23Wx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VFW7IQN3nGw"
      },
      "source": [
        "Apply K-Means Clustering with 5 Clusters on the `features` Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW42NbueuByN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmQsXruiibQN"
      },
      "source": [
        "### Task 4 - Visualize the clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcKNghIQ7tmW"
      },
      "source": [
        "Let's reduce the dimensionality of our features for visualization purpose\n",
        "\n",
        "`512 dimensions => 2 dimensions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4nInmIO3kef"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTDBB6hfl5B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aKKtmrtz6JI"
      },
      "source": [
        "Let's plot the Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyWDqBw63yyo"
      },
      "outputs": [],
      "source": [
        "def plot_clusters(pca_df, num_clusters=5):\n",
        "    \"\"\"\n",
        "    Plots a 2D visualization of clusters using Plotly Express.\n",
        "\n",
        "    Parameters:\n",
        "    - pca_df (DataFrame): A Pandas DataFrame containing columns 'x', 'y', and 'cluster'.\n",
        "      'x' and 'y' are the 2D PCA components, and 'cluster' indicates the cluster label.\n",
        "    - num_clusters (int): The number of unique clusters to display.\n",
        "    - recently_viewed_df (DataFrame, optional): DataFrame with 'x' and 'y' coordinates for recently viewed products.\n",
        "\n",
        "    This function creates an interactive scatter plot where each point is colored according to its cluster.\n",
        "    Recently viewed products are marked as black crosses if provided.\n",
        "\n",
        "    Returns:\n",
        "    - fig (Figure): The Plotly figure object for the plot.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the base cluster plot\n",
        "    fig = px.scatter(\n",
        "        pca_df,\n",
        "        x='x',\n",
        "        y='y',\n",
        "        opacity=0.6,\n",
        "        size_max=4,\n",
        "        color= pca_df.cluster.astype(str),\n",
        "        title='2D Visualization of Clusters with Recently Viewed Products',\n",
        "        labels={'x': 'PCA Component 1', 'y': 'PCA Component 2'},\n",
        "        category_orders={'cluster': list(range(num_clusters))},\n",
        "        # show the product id in the tooltip\n",
        "        hover_data={'product_id': True}\n",
        "\n",
        "    )\n",
        "\n",
        "    # Update layout to add legend title and adjust plot settings\n",
        "    fig.update_layout(legend_title_text='Clusters', legend=dict(x=1, y=1), width=600, height=500)\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_clusters(pca_df)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUf0_1QE9x36"
      },
      "source": [
        "### Task 5 - Highlight recently viewed products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aVSaE-194HQ"
      },
      "outputs": [],
      "source": [
        "print(\"The user has recently viewed the following products: \", recently_viewed_products)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7XYwmVhKviT"
      },
      "source": [
        "Let's have a look at the records in our `clustered_data` dataframe related to the recently viewed products."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G__WrqP3RreI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgvR7IZBdfRP"
      },
      "source": [
        "### Task 6 - Recommend products based on recently viewed products"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the recently viewed products titles"
      ],
      "metadata": {
        "id": "WGXK0C8iHcqv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_fSozf6Hi5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VDv_TunhyAx"
      },
      "source": [
        "Let's see the distinct clusters of the recenetly viewed products."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcIpAoXdDgjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmoLOKthh2f_"
      },
      "source": [
        "Let's find the possible products for the recommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unKBWkemiLR4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZxLGRiN41hy"
      },
      "source": [
        "Let's perform a groupby and generate a list of product IDs that can be recommended for each of the clusters."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iW0uDP6vRxvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdjExGZS5HNV"
      },
      "outputs": [],
      "source": [
        "# write a python function to display the recommendations\n",
        "def display_recommendations(row):\n",
        "  # find the title of the product in df\n",
        "  product_ids = row['random_recommendations']\n",
        "  cluster = row.cluster\n",
        "\n",
        "  titles = data. \\\n",
        "          filter(data[\"product_id\"]. \\\n",
        "          isin(product_ids)).select(\"title\").collect()\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"Recommendations for Cluster:\", cluster)\n",
        "  for title in titles:\n",
        "    print(title[0])\n",
        "\n",
        "recommendations_df.apply(display_recommendations, axis=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WSq024bak3oY",
        "p8GVRghclHxs",
        "hY4One5i4VXh",
        "tmQsXruiibQN",
        "wUf0_1QE9x36",
        "IgvR7IZBdfRP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}